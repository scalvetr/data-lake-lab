version: "3.5"
services:

  zookeeper:
    image: zookeeper:3.6.2
    hostname: zookeeper
    container_name: big-data-lab-zookeeper
    expose:
      - 2181
    volumes:
      #- zookeeper-logs:/logs
      - ./ws/zookeeper/logs:/logs
      #- zookeeper-data:/data
    networks:
      - big-data-lab-net

  kafka:
    image: wurstmeister/kafka:2.13-2.6.0
    hostname: kafka
    container_name: big-data-lab-kafka
    command: [start-kafka.sh]
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092
      KAFKA_LISTENERS: INSIDE://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - ./ws/kafka/logs:/kafka/logs
      #- kafka-logs:/kafka/logs
    networks:
      - big-data-lab-net
    depends_on:
      - zookeeper

  nifi:
    image: apache/nifi:1.12.1
    hostname: nifi
    container_name: big-data-lab-nifi
    environment:
      NIFI_WEB_HTTP_PORT: 9081
      NIFI_WEB_HTTPS_PORT: 9443
    ports:
      - "9081:9081"
      - "9443:9443"
    volumes:
      - ./ws/nifi/logs:/opt/nifi/nifi-current/logs
      - ./ws/shared:/opt/workspace
      #- nifi-logs:/opt/nifi/nifi-current/logs
      #- shared-workspace:/opt/workspace
    networks:
      - big-data-lab-net
    depends_on:
      - zookeeper
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    hostname: elasticsearch
    container_name: big-data-lab-elasticsearch
    volumes:
      - ./ws/elasticsearch/logs:/usr/share/elasticsearch/logs/
    environment:
      discovery.type: single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - big-data-lab-net

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.1
    hostname: kibana
    container_name: big-data-lab-kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
    networks:
      - big-data-lab-net
    depends_on:
      - elasticsearch

  hdfs-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    hostname: hdfs-namenode
    container_name: big-data-lab-hdfs-namenode
    volumes:
      - ./ws/hadoop/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=big-data-lab
    ports:
      - "50070:50070"
    networks:
      - big-data-lab-net

  hdfs-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    hostname: hdfs-datanode
    container_name: big-data-lab-hdfs-datanode
    volumes:
      - ./ws/hadoop/datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:50070"
      CORE_CONF_fs_defaultFS: "hdfs://hdfs-namenode:8020"
    depends_on:
      - hdfs-namenode
    ports:
      - "50075:50075"
    networks:
      - big-data-lab-net

  spark-master:
    image: bde2020/spark-master:2.4.0-hadoop2.7
    container_name: big-data-lab-spark-master
    ports:
      - 8080:8080
      - 7077:7077
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://hdfs-namenode:8020"
    networks:
      - big-data-lab-net

  spark-worker:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    container_name: big-data-lab-spark-worker
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
      CORE_CONF_fs_defaultFS: "hdfs://hdfs-namenode:8020"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
    ports:
      - 8081:8081
    networks:
      - big-data-lab-net


  zeppelin:
    build:
      context: docker/zeppelin/
      labels:
        - scalvetr/spark
    hostname: zeppelin
    container_name: big-data-lab-zeppelin
    ports:
      - "9080:8080"
    environment:
      ZEPPELIN_LOG_DIR: /zeppelin/logs
      ZEPPELIN_NOTEBOOK_DIR: /zeppelin/notebook
      HADOOP_USER_NAME: root
    volumes:
      - ./ws/shared:/opt/workspace
      - ./ws/zeppelin/notebooks:/zeppelin/notebook
      - ./ws/zeppelin/logs:/zeppelin/logs
      - ./ws/zeppelin/conf/log4j.properties:/zeppelin/conf/log4j.properties
      - ./ws/zeppelin/conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./ws/zeppelin/conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      #- shared-workspace:/opt/workspace
      #- zeppelin-notebooks:/zeppelin/notebook
      #- zeppelin-logs:/zeppelin/logs
    networks:
      - big-data-lab-net

networks:
  big-data-lab-net:
    name: "big-data-lab-net"
    driver: bridge

volumes:
  zookeeper-data:
    name: "big-data-lab-zookeeper-data"
    driver: local
