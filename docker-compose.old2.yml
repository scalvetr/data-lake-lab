version: "3.5"
services:

  zookeeper:
    image: zookeeper:3.6.2
    hostname: zookeeper
    container_name: data-lake-zookeeper
    expose:
      - 2181
    volumes:
      #- zookeeper-logs:/logs
      - ./ws/zookeeper/logs:/logs
      #- zookeeper-data:/data
    networks:
      - big-data-lab-net

  kafka:
    image: wurstmeister/kafka:2.13-2.6.0
    hostname: kafka
    container_name: data-lake-kafka
    command: [start-kafka.sh]
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092
      KAFKA_LISTENERS: INSIDE://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - ./ws/kafka/logs:/kafka/logs
      #- kafka-logs:/kafka/logs
    networks:
      - big-data-lab-net
    depends_on:
      - zookeeper

  nifi:
    image: apache/nifi:1.12.1
    hostname: nifi
    container_name: data-lake-nifi
    environment:
      NIFI_WEB_HTTP_PORT: 8082
      NIFI_WEB_HTTPS_PORT: 8445
    ports:
      - "8082:8082"
      - "8445:8445"
    volumes:
      - ./ws/nifi/logs:/opt/nifi/nifi-current/logs
      - ./ws/shared:/opt/workspace
    networks:
      - big-data-lab-net
    depends_on:
      - zookeeper
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    hostname: elasticsearch
    container_name: data-lake-elasticsearch
    volumes:
      - ./ws/elasticsearch/logs:/usr/share/elasticsearch/logs/
    environment:
      discovery.type: single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - big-data-lab-net

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.1
    hostname: kibana
    container_name: data-lake-kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
    networks:
      - big-data-lab-net
    depends_on:
      - elasticsearch

  hdfs-namenode:
    image: cybermaggedon/hadoop:2.10.0
    hostname: hdfs-namenode
    container_name: data-lake-hdfs-namenode
    ports:
      - "9000:9000"
      - "8020:8020"
      - "50070:50070"
    volumes:
      - ./ws/shared:/opt/workspace
      - ./ws/hadoop/logs:/usr/local/hadoop/logs/
      - ./ws/hadoop/data:/data
    networks:
      - big-data-lab-net

  spark:
    #image: apache/zeppelin:0.9.0
    build:
      context: docker/spark/
      args:
        ZEPPELIN_HOME: /zeppelin
      labels:
        - scalvetr/spark
    hostname: spark
    container_name: data-lake-spark
    ports:
      - "7077:7077"
      - "8080:8080"
      - "8081:8081"
      - "8443:8443"
      - "4040:4040"
    environment:
      SPARK_MODE: master
      ZEPPELIN_LOG_DIR: /zeppelin/logs
      ZEPPELIN_NOTEBOOK_DIR: /zeppelin/notebook
    volumes:
      - ./ws/shared:/opt/workspace
      - ./ws/zeppelin/notebooks:/zeppelin/notebook
      - ./ws/zeppelin/logs:/zeppelin/logs
      - ./ws/zeppelin/conf/log4j.properties:/zeppelin/conf/log4j.properties
    networks:
      - big-data-lab-net

networks:
  big-data-lab-net:
    name: "big-data-lab-net"
    driver: bridge

volumes:
  zookeeper-data:
    name: "big-data-lab-zookeeper-data"
    driver: local
